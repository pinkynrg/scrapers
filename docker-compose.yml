services:
  api:
    image: pinkynrg/scrapers:latest
    container_name: scrapers-api
    ports:
      - "8008:8000"
    volumes:
      - /mnt/data/scrapers/data:/app/data
    environment:
      - DB_PATH=/app/data/scrapers.db
    command: python api.py
    restart: always

  linkedin-scraper:
    image: pinkynrg/scrapers:latest
    container_name: linkedin-scraper
    volumes:
      - /mnt/data/scrapers/data:/app/data
      - /mnt/data/scrapers/state:/app/state
    environment:
      - DB_PATH=/app/data/scrapers.db
      - LINKEDIN_URL=https://www.linkedin.com/jobs/search/?currentJobId=4345767493&f_E=4&f_WT=2&keywords=python%20react%20docker&origin=JOB_SEARCH_PAGE_JOB_FILTER
      - STATE_DIRECTORY=/app/state
      - LOCAL=false
      - SCRAPE_INTERVAL=3600  # Run every 60 minutes (in seconds)
    command: >
      sh -c "while true; do
        echo 'Starting LinkedIn scraper...';
        python crawlers/linkedin.py;
        echo 'LinkedIn scraper completed. Sleeping for $$SCRAPE_INTERVAL seconds...';
        sleep $SCRAPE_INTERVAL;
      done"
    restart: always

  blog-scraper:
    image: pinkynrg/scrapers:latest
    container_name: blog-scraper
    volumes:
      - /mnt/data/scrapers/data:/app/data
      - /mnt/data/scrapers/state:/app/state
    environment:
      - DB_PATH=/app/data/scrapers.db
      - BLOG_URL=https://blog.francescomeli.com
      - LOCAL=false
      - SCRAPE_INTERVAL=1800  # Run every 30 minutes (in seconds)
    command: >
      sh -c "while true; do
        echo 'Starting blog scraper...';
        python crawlers/blog.py;
        echo 'Blog scraper completed. Sleeping for $$SCRAPE_INTERVAL seconds...';
        sleep $SCRAPE_INTERVAL;
      done"
    restart: always
